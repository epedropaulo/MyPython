{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar, vamos importar os pacotes básicos para o código que temos a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd \n",
    "import math\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.graphics.regressionplots import *\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.1 Conjunto de validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos os dados `Auto`, descartando as observação com entradas NAs.\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = pd.read_csv('../data/Auto.csv', header=0, na_values='?')\n",
    "Auto = Auto.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "print(Auto.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
      "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
      "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
      "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
      "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
      "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n"
     ]
    }
   ],
   "source": [
    "print(Auto.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como lidaremos com splits aleatórios, precisamos fixar um seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos gerar o conjunto de treino e teste escolhendo metade da amostra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(Auto.shape[0], 196, replace=False)\n",
    "in_train = np.in1d(range(Auto.shape[0]), train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos selecionar os dados de treino `Auto[in_train]` para treinar uma regressão linear de `mpg` em `horsepower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.620\n",
      "Model:                            OLS   Adj. R-squared:                  0.618\n",
      "Method:                 Least Squares   F-statistic:                     316.4\n",
      "Date:                Tue, 08 Nov 2022   Prob (F-statistic):           1.28e-42\n",
      "Time:                        10:21:08   Log-Likelihood:                -592.07\n",
      "No. Observations:                 196   AIC:                             1188.\n",
      "Df Residuals:                     194   BIC:                             1195.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     40.3338      1.023     39.416      0.000      38.316      42.352\n",
      "horsepower    -0.1596      0.009    -17.788      0.000      -0.177      -0.142\n",
      "==============================================================================\n",
      "Omnibus:                        8.393   Durbin-Watson:                   1.061\n",
      "Prob(Omnibus):                  0.015   Jarque-Bera (JB):                8.787\n",
      "Skew:                           0.516   Prob(JB):                       0.0124\n",
      "Kurtosis:                       2.899   Cond. No.                         328.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lm = smf.ols('mpg~horsepower', data = Auto[in_train]).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver como o modelo se comporta no treino e no teste em termos de erro médio quadrático (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for 1st order model: 24.62301015144335\n"
     ]
    }
   ],
   "source": [
    "preds_train = lm.predict(Auto[in_train])\n",
    "MSE = np.mean((Auto['mpg'][in_train] - preds_train)**2)\n",
    "print(f\"Train error for 1st order model: {MSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error for 1st order model: 23.361902892587224\n"
     ]
    }
   ],
   "source": [
    "in_test = ~in_train\n",
    "preds_test = lm.predict(Auto[in_test])\n",
    "MSE = np.mean((Auto['mpg'][in_test] - preds_test)**2)\n",
    "print(f\"Test error for 1st order model: {MSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curiosamente, parece que nosso erro de teste é melhor do que de treino. Isso em geral é sinal de que poderíamos usar um modelo mais flexível para os dados. Uma possibilidade é incluir mais previsores. Vamos olhar para o erro de teste incluindo um modelo quadrático e um cúbico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error for 2nd order model: 20.252690858350043\n"
     ]
    }
   ],
   "source": [
    "lm2 = smf.ols('mpg~horsepower + I(horsepower ** 2.0)', data = Auto[in_train]).fit()\n",
    "preds_test = lm2.predict(Auto[in_test])\n",
    "MSE = np.mean((Auto['mpg'][in_test] - preds_test)**2)\n",
    "print(f\"Test error for 2nd order model: {MSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error for 3rd order model: 20.325609365773598\n"
     ]
    }
   ],
   "source": [
    "lm3 = smf.ols('mpg~horsepower + I(horsepower ** 2.0) + I(horsepower ** 3.0)', data = Auto[in_train]).fit()\n",
    "preds_test = lm3.predict(Auto[in_test])\n",
    "MSE = np.mean((Auto['mpg'][in_test] - preds_test)**2)\n",
    "print(f\"Test error for 3rd order model: {MSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como assinalado no livro, um modelo quadrático parece razoável, e um modelo cúbico parece mais flexível do que o necessário. Uma outra evidência para isso é o p-valor do termo cúbico, que não é estatisticamente signficativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.722\n",
      "Model:                            OLS   Adj. R-squared:                  0.717\n",
      "Method:                 Least Squares   F-statistic:                     165.9\n",
      "Date:                Tue, 08 Nov 2022   Prob (F-statistic):           4.60e-53\n",
      "Time:                        10:37:41   Log-Likelihood:                -561.56\n",
      "No. Observations:                 196   AIC:                             1131.\n",
      "Df Residuals:                     192   BIC:                             1144.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               66.5200      6.310     10.541      0.000      54.073      78.967\n",
      "horsepower              -0.6868      0.162     -4.238      0.000      -1.006      -0.367\n",
      "I(horsepower ** 2.0)     0.0028      0.001      2.157      0.032       0.000       0.005\n",
      "I(horsepower ** 3.0) -3.524e-06   3.27e-06     -1.078      0.282   -9.97e-06    2.92e-06\n",
      "==============================================================================\n",
      "Omnibus:                        9.054   Durbin-Watson:                   1.328\n",
      "Prob(Omnibus):                  0.011   Jarque-Bera (JB):               15.936\n",
      "Skew:                           0.174   Prob(JB):                     0.000346\n",
      "Kurtosis:                       4.353   Cond. No.                     5.83e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.83e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(lm3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estimativa de erro via LOOCV é feita usando cada ponto dos dados como o conjunto de validação (com o resto dos dados para treino) e depois tirando a média. Para rodar LOOCV, é conveniente usar scikit-learn. Vamos primeiro nos certificar de que os resultados usando o `statsmodels` e `sklearn` são iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept     39.935861\n",
      "horsepower    -0.157845\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ols_fit = smf.ols('mpg~horsepower', data = Auto).fit()\n",
    "print(ols_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.93586102117047\n",
      "[-0.15784473]\n"
     ]
    }
   ],
   "source": [
    "# let us re-train the model in sklearn\n",
    "X = pd.DataFrame(Auto.horsepower)\n",
    "y = Auto.mpg\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar LOOCV, podemos ou usar a função `LeaveOneOut()` ou, notando que LOOCV é equivalente a CV com $k=n$, usar a função `KFold()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.231513517929226\n"
     ]
    }
   ],
   "source": [
    "cv=LeaveOneOut()\n",
    "# cv = KFold(n_splits=X.shape[0]) \n",
    "cv_test_errors = cross_val_score(model, X, y, cv=k_fold, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "print(np.mean(-cv_test_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos repetir esse procedimento para regressões polinomiais cada vez mais complexas e investigar o erro estimado por LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order 1: 24.231513517929226\n",
      "Order 3: 19.334984064089344\n",
      "Order 5: 19.033202860364923\n",
      "Order 7: 19.125945340185698\n",
      "Order 9: 19.133992634311166\n",
      "Order 11: 19.093575370871264\n",
      "Order 13: 27.76342373851964\n",
      "Order 15: 35.29331546501886\n",
      "Order 17: 43.654384822868444\n",
      "Order 19: 60.96645503434402\n"
     ]
    }
   ],
   "source": [
    "for poly_order in range(1, 21, 2):\n",
    "    model = Pipeline([('polynomial_regression', PolynomialFeatures(degree=poly_order)), ('linear', LinearRegression())])\n",
    "    cv_test_errors = cross_val_score(model, X, y, cv=cv,  scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "    print(f\"Order {poly_order}: {np.mean(-cv_test_errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente deveríamos escolher o modelo de ordem 3, pois é o que tem menor erro de LOOCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.3 k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rodar $k$-fold CV, basta usar escolher o número de folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order 1: 27.439933652339864\n",
      "Order 3: 21.336606183332187\n",
      "Order 5: 20.9055947045051\n",
      "Order 7: 20.953025341423164\n",
      "Order 9: 21.035364180513188\n",
      "Order 11: 21.428606258458796\n",
      "Order 13: 30.81009154986064\n",
      "Order 15: 39.53674933663759\n",
      "Order 17: 48.27499940440114\n",
      "Order 19: 64.0239576185277\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "k = 10\n",
    "\n",
    "for poly_order in range(1, 21, 2):\n",
    "    model = Pipeline([('polynomial_regression', PolynomialFeatures(degree=poly_order)), ('linear', LinearRegression())])\n",
    "    k_fold = KFold(n_splits=k) \n",
    "    cv_test_errors = cross_val_score(model, X, y, cv=k_fold,  scoring = 'neg_mean_squared_error', n_jobs = -1)\n",
    "    print(f\"Order {poly_order}: {np.mean(-cv_test_errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.4 Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap significa estimar incerteza nos dados via reamostragem com reposição. Usamos amostras dos dados originais preservando o mesmo tamanho total dos dados para evitar que efeitos de tamanho da amostra influenciem nas estimativas. Essa técnica é muito útil para desenvolver intervalos de confiança e testes de hipótese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta subseção, vamos usar os dados `Portfolio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = pd.read_csv('../data/Portfolio.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar o bootstrap, primeiro criamos uma função que recebe uma replicação dos dados e retorna a quantidade de interesse. Seguindo o exemplo do texto, vamos escolher a função $\\alpha$, definida em (5.7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_fn(data, index):\n",
    "    X = data.X.iloc[index]\n",
    "    Y = data.Y.iloc[index]\n",
    "    return (np.var(Y) - np.cov(X,Y)[0,1])/(np.var(X) + np.var(Y) - 2 * np.cov(X, Y)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, suponha que queiramos o valor de `alpha_fn()` calculada nas primeiras 100 instâncias dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5766511516104116"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_fn(Portfolio, range(0,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos gerar uma amostra com reposição de um conjunto de índices, satisfazendo um certo tamanho total. Vamos usar algumas funções de Numpy para isso, e depois instanciar a função `alpha_fn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  2,  5,  6,  6,  7,  7,  7,  9, 10, 10, 10, 12, 13, 13, 13,\n",
       "       14, 15, 15, 17, 20, 20, 20, 21, 21, 21, 22, 23, 24, 24, 24, 25, 30,\n",
       "       32, 36, 36, 40, 42, 43, 43, 45, 47, 48, 48, 49, 52, 53, 53, 54, 54,\n",
       "       55, 56, 56, 57, 59, 60, 61, 65, 66, 66, 68, 69, 70, 70, 71, 71, 72,\n",
       "       74, 75, 75, 76, 76, 77, 77, 77, 77, 77, 81, 82, 82, 82, 83, 84, 84,\n",
       "       85, 86, 89, 91, 91, 92, 92, 94, 96, 96, 96, 96, 97, 97, 98])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.random.choice(range(0, 100), size=100, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4750231770084347"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall the previous function with a random set of input. \n",
    "alpha_fn(Portfolio, np.random.choice(range(0, 100), size=100, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o resultado é diferente da função calculada nos 100 primeiros índices dos dados, pois o valor acima usa uma amostra diferente. O importante é que, tomando várias amostras de 100 indíces escolhidas com reposição, ganhamos uma estimativa válida da variabilidade de `alpha_fn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_python(data, input_function, replications):\n",
    "    n = Portfolio.shape[0]\n",
    "    sample_replications = np.random.randint(0, n, (replications, n))  # draw (replications) samples with numbers from 0 to n\n",
    "    bootstrap_replications = np.zeros(replications)\n",
    "    for i in range(len(sample_replications)):\n",
    "        bootstrap_replications[i] = input_function(data, sample_replications[i])\n",
    "    \n",
    "    return {'Mean': np.mean(bootstrap_replications), 'std. dev': np.std(bootstrap_replications)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean': 0.5798295835545277, 'std. dev': 0.09547521666592128}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_python(Portfolio, alpha_fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, em média a função `alpha_fn` nos dados é 0.58, com um desvio padrão de 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "4548a0e672c5b3a287feee7b2962606840aa548749d1830ef724408652b0c250"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
